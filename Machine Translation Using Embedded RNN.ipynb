{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10157303,"sourceType":"datasetVersion","datasetId":6265059}],"dockerImageVersionId":30804,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# I210503 Muhammad Zian Ahmed\n# I212562 Humayun Malik\n# NLP - D\n# Project","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport random\n\n# Load Urdu and English datasets\nwith open('/kaggle/input/nlpproject/urd_Arab.dev', 'r', encoding='utf-8') as f:\n    urd_dev = f.readlines()\n\nwith open('/kaggle/input/nlpproject/urd_Arab.devtest', 'r', encoding='utf-8') as f:\n    urd_devtest = f.readlines()\n\nwith open('/kaggle/input/nlpproject/eng_Latn.dev', 'r', encoding='utf-8') as f:\n    eng_dev = f.readlines()\n\nwith open('/kaggle/input/nlpproject/eng_Latn.devtest', 'r', encoding='utf-8') as f:\n    eng_devtest = f.readlines()\n\n# Combine datasets\nurdu_sentences = urd_dev + urd_devtest\nenglish_sentences = eng_dev + eng_devtest\n\n# Ensure both datasets have the same number of sentences\nassert len(urdu_sentences) == len(english_sentences), \"Datasets are not aligned!\"\n\n# Create a DataFrame\ndata = pd.DataFrame({\n    'urdu': [sentence.strip() for sentence in urdu_sentences],\n    'english': [sentence.strip() for sentence in english_sentences]\n})\n\n# Shuffle the data\ndata = data.sample(frac=1, random_state=42).reset_index(drop=True)\n\n# Split into training, validation, and test sets\ntrain_size = int(0.7 * len(data))\nval_size = int(0.15 * len(data))\n\ntrain_data = data[:train_size]\nval_data = data[train_size:train_size + val_size]\ntest_data = data[train_size + val_size:]\n\n# Save splits to files\ntrain_data.to_csv('train.csv', index=False)\nval_data.to_csv('val.csv', index=False)\ntest_data.to_csv('test.csv', index=False)\n\nprint(\"Data preprocessing complete. Files saved as 'train.csv', 'val.csv', and 'test.csv'.\")\n\n\n# Print dataset lengths and first 5 samples\nprint(f\"Number of Urdu sentences: {len(urdu_sentences)}\")\nprint(f\"Number of English sentences: {len(english_sentences)}\")\nprint(\"\\nSample Urdu sentences:\", urdu_sentences[:5])\nprint(\"\\nSample English sentences:\", english_sentences[:5])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_d66TAsaJ870","outputId":"10b78590-eea0-4014-80e3-b2fc8c1e5eff","trusted":true,"execution":{"iopub.status.busy":"2024-12-10T14:05:05.030428Z","iopub.execute_input":"2024-12-10T14:05:05.030909Z","iopub.status.idle":"2024-12-10T14:05:05.084521Z","shell.execute_reply.started":"2024-12-10T14:05:05.030871Z","shell.execute_reply":"2024-12-10T14:05:05.083386Z"}},"outputs":[{"name":"stdout","text":"Data preprocessing complete. Files saved as 'train.csv', 'val.csv', and 'test.csv'.\nNumber of Urdu sentences: 2009\nNumber of English sentences: 2009\n\nSample Urdu sentences: ['پیر کے روز، سٹینفورڈ اسکول آف میڈیسن کے سائنسدانوں نے ایک جدید تشخیصی آلہ دریافت کرنے کا اعلان کیا ہے جو خلیوں کو اس کی اقسام کے لحاظ سے ترتیب دے سکتا ہے: یہ ایک چھوٹی سی پرنٹیبل چپ ہے جو غالباً ایک امریکی سنٹ میں معیاری انک جیٹ پرنٹرز کا استعمال کر کے تیار کی جا سکتی ہے-\\n', 'سرکردہ محققین کہتے ہیں کہ اس سے کم آمدنی والے ممالک کے مریضوں میں کینسر، تپ و دق، ایچ آئی وی اور ملیریا کا جلد پتہ چل سکتا ہے، جہاں چھاتی کے کینسر جیسی بیماریوں سے بچنے کی شرح امیر ممالک کی مقابلے میں نصف ہو سکتی ہے۔\\n', 'مقامی وقت کے مطابق تقریبا صبح 9:30 بجے (0230 UTC) 39C JASگریپین رن وے پر ٹکرا کر دھماکے کے ساتھ پھٹ کر تباہ ہو گیا، جس کے باعث ہوائی اڈے کی تجارتی پروازیں بند کرنی پڑیں-\\n', 'پائلٹ کو اسکواڈرن لیڈر ڈیلوکرٹ پٹاوی کے نام سے شناخت کیا گیا۔\\n', 'مقامی میڈیا نے بتایا کہ ہوائی اڈے کی ایک آگ بھجانے والی گاڑی کاروائی کرتے وقت الٹ گئی۔\\n']\n\nSample English sentences: ['On Monday, scientists from the Stanford University School of Medicine announced the invention of a new diagnostic tool that can sort cells by type: a tiny printable chip that can be manufactured using standard inkjet printers for possibly about one U.S. cent each.\\n', 'Lead researchers say this may bring early detection of cancer, tuberculosis, HIV and malaria to patients in low-income countries, where the survival rates for illnesses such as breast cancer can be half those of richer countries.\\n', 'The JAS 39C Gripen crashed onto a runway at around 9:30 am local time (0230 UTC) and exploded, closing the airport to commercial flights.\\n', 'The pilot was identified as Squadron Leader Dilokrit Pattavee.\\n', 'Local media reports an airport fire vehicle rolled over while responding.\\n']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import re\n\n# Tokenizer for Urdu\ndef tokenize_urdu(sentence):\n    return re.findall(r'\\w+|[^\\s\\w]', sentence, re.UNICODE)\n\n# Tokenizer for English\ndef tokenize_english(sentence):\n    return re.findall(r'\\w+|[^\\s\\w]', sentence)\n\n# Tokenize training, validation, and test data\ndef tokenize_dataset(dataset):\n    urdu_tokenized = dataset['urdu'].apply(tokenize_urdu)\n    english_tokenized = dataset['english'].apply(tokenize_english)\n    return urdu_tokenized, english_tokenized\n\n# Tokenize each split\ntrain_urdu, train_english = tokenize_dataset(train_data)\nval_urdu, val_english = tokenize_dataset(val_data)\ntest_urdu, test_english = tokenize_dataset(test_data)\n\n# Save tokenized data\ntrain_tokenized = pd.DataFrame({'urdu': train_urdu, 'english': train_english})\nval_tokenized = pd.DataFrame({'urdu': val_urdu, 'english': val_english})\ntest_tokenized = pd.DataFrame({'urdu': test_urdu, 'english': test_english})\n\ntrain_tokenized.to_csv('train_tokenized.csv', index=False)\nval_tokenized.to_csv('val_tokenized.csv', index=False)\ntest_tokenized.to_csv('test_tokenized.csv', index=False)\n\nprint(\"Tokenized data saved as 'train_tokenized.csv', 'val_tokenized.csv', and 'test_tokenized.csv'.\")\n\n# Print first 5 samples of each split\nprint(\"\\nTraining samples:\\n\", train_data.head())\nprint(\"\\nValidation samples:\\n\", val_data.head())\nprint(\"\\nTest samples:\\n\", test_data.head())\n\n\n# Print first 5 tokenized samples\nprint(\"\\nTokenized Training Urdu Sentences:\\n\", train_urdu.head())\nprint(\"\\nTokenized Training English Sentences:\\n\", train_english.head())\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lMrOnMBSKATO","outputId":"943e99ce-d17b-48b8-eef0-089da98a08cd","trusted":true,"execution":{"iopub.status.busy":"2024-12-10T14:05:05.086731Z","iopub.execute_input":"2024-12-10T14:05:05.088074Z","iopub.status.idle":"2024-12-10T14:05:05.226971Z","shell.execute_reply.started":"2024-12-10T14:05:05.088018Z","shell.execute_reply":"2024-12-10T14:05:05.225652Z"}},"outputs":[{"name":"stdout","text":"Tokenized data saved as 'train_tokenized.csv', 'val_tokenized.csv', and 'test_tokenized.csv'.\n\nTraining samples:\n                                                 urdu  \\\n0  بہت سے لوگوں کا مشاہدہ ہے کہ فعلیات اور برتاؤ ...   \n1  باردیا کے مشرق میں کمین لگا کر برٹش نے اطالوی ...   \n2  جرمنی نے اس حملے کو \"آپریشن سی لاین\" نام دیا۔ ...   \n3  ڈی- ڈے لینڈنگ اور اس کے بعد کی لڑائیوں کے نتیج...   \n4  بیلجیئم کے آج کے دور کے حصے ماضی میں لگزمبرگ ک...   \n\n                                             english  \n0  Many observed rhythms in physiology and behavi...  \n1  In an ambush east of Bardia, the British captu...  \n2  Germany code-named the attack “Operation Seali...  \n3  The D-Day landings and the following battles h...  \n4  Present-day parts of Belgium were part of Luxe...  \n\nValidation samples:\n                                                    urdu  \\\n1406       کینیڈا کا خلاف نڈال کے رو برو ریکارڈ 7–2 ہے۔   \n1407  آو ہم اٹلی کے پلانس کی تشریح سے بات شروع کریں۔...   \n1408  پچھلے ماہ پولینڈ میں اس وقت بھاری احتجاج ہوا ج...   \n1409  اس کا استقبال سنگاپور کے نائب وزیر اعظم وونگ ک...   \n1410  اگست میں ایمز اسٹرا پول جیتنے والی، بیک مین نے...   \n\n                                                english  \n1406  Nadal's head to head record against the Canadi...  \n1407  Let's start with an explanation about Italy's ...  \n1408  Last month, there were major protests in Polan...  \n1409  He was greeted by Singapore's Deputy Prime Min...  \n1410  Bachmann, who won the Ames Straw Poll in Augus...  \n\nTest samples:\n                                                    urdu  \\\n1707  میڈیکل چیرٹی منگولا، میڈیسنس سینس فرنٹیئرز اور...   \n1708  بعد اس کے کہ دونوں افراد نے سیٹ کے ہر ایک سرو ...   \n1709  وقت یہ بھی ہے کہ ہم کس طرح واقعات کے دورانیے (...   \n1710  \"اس رکاز کی بُنیاد پر اس کا مطلب یہ ہے کہ یہ ش...   \n1711  کسی پرائویٹ پراپرٹی پر یا جسی بھی حجم کے ٹاؤن ...   \n\n                                                english  \n1707  The medical charity Mangola, Medecines Sans Fr...  \n1708  Murray lost the first set in a tie break after...  \n1709  Time is also how we compare the duration (leng...  \n1710  \"Based on this fossil, that means the split is...  \n1711  Setting up a tent on private property or in a ...  \n\nTokenized Training Urdu Sentences:\n 0    [بہت, سے, لوگوں, کا, مشاہدہ, ہے, کہ, فعلیات, ا...\n1    [باردیا, کے, مشرق, میں, کمین, لگا, کر, برٹش, ن...\n2    [جرمنی, نے, اس, حملے, کو, \", آپریشن, سی, لاین,...\n3    [ڈی, -, ڈے, لینڈنگ, اور, اس, کے, بعد, کی, لڑائ...\n4    [بیلجیئم, کے, آج, کے, دور, کے, حصے, ماضی, میں,...\nName: urdu, dtype: object\n\nTokenized Training English Sentences:\n 0    [Many, observed, rhythms, in, physiology, and,...\n1    [In, an, ambush, east, of, Bardia, ,, the, Bri...\n2    [Germany, code, -, named, the, attack, “, Oper...\n3    [The, D, -, Day, landings, and, the, following...\n4    [Present, -, day, parts, of, Belgium, were, pa...\nName: english, dtype: object\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from collections import Counter\n\ndef build_vocab(sentences):\n    word_counts = Counter([word for sentence in sentences for word in sentence])\n    vocab = {word: idx for idx, (word, _) in enumerate(word_counts.most_common(), start=4)}\n    vocab['<pad>'] = 0\n    vocab['<sos>'] = 1\n    vocab['<eos>'] = 2\n    vocab['<unk>'] = 3\n    return vocab\n\n# Build vocabularies\nurdu_vocab = build_vocab(train_urdu)\nenglish_vocab = build_vocab(train_english)\n\n# Save vocabularies\nimport json\n\nwith open('urdu_vocab.json', 'w') as f:\n    json.dump(urdu_vocab, f)\n\nwith open('english_vocab.json', 'w') as f:\n    json.dump(english_vocab, f)\n\nprint(\"Vocabularies saved as 'urdu_vocab.json' and 'english_vocab.json'.\")\n\n\n# Print vocabulary sizes and first 10 words\nprint(f\"Urdu Vocabulary Size: {len(urdu_vocab)}\")\nprint(f\"English Vocabulary Size: {len(english_vocab)}\")\n\nprint(\"\\nSample Urdu Vocabulary:\\n\", dict(list(urdu_vocab.items())[:10]))\nprint(\"\\nSample English Vocabulary:\\n\", dict(list(english_vocab.items())[:10]))\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gXq-bSpAKExH","outputId":"e62e91c7-355c-4904-9dbb-703792ff9c87","trusted":true,"execution":{"iopub.status.busy":"2024-12-10T14:05:05.228617Z","iopub.execute_input":"2024-12-10T14:05:05.229063Z","iopub.status.idle":"2024-12-10T14:05:05.298936Z","shell.execute_reply.started":"2024-12-10T14:05:05.229028Z","shell.execute_reply":"2024-12-10T14:05:05.297410Z"}},"outputs":[{"name":"stdout","text":"Vocabularies saved as 'urdu_vocab.json' and 'english_vocab.json'.\nUrdu Vocabulary Size: 7266\nEnglish Vocabulary Size: 7498\n\nSample Urdu Vocabulary:\n {'کے': 4, '۔': 5, 'کی': 6, 'ہے': 7, 'میں': 8, '،': 9, 'سے': 10, 'اور': 11, 'کو': 12, 'ہیں': 13}\n\nSample English Vocabulary:\n {'the': 4, '.': 5, ',': 6, 'of': 7, 'and': 8, 'to': 9, 'a': 10, 'in': 11, 'is': 12, 'The': 13}\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def sentence_to_indices(sentence, vocab, max_len=50):\n    indices = [vocab.get(word, vocab['<unk>']) for word in sentence]\n    indices = [vocab['<sos>']] + indices[:max_len-2] + [vocab['<eos>']]\n    return indices + [vocab['<pad>']] * (max_len - len(indices))\n\ndef dataset_to_indices(urdu_sentences, english_sentences, urdu_vocab, english_vocab, max_len=50):\n    urdu_indices = urdu_sentences.apply(lambda x: sentence_to_indices(x, urdu_vocab, max_len))\n    english_indices = english_sentences.apply(lambda x: sentence_to_indices(x, english_vocab, max_len))\n    return urdu_indices, english_indices\n\n# Convert datasets to indices\ntrain_urdu_indices, train_english_indices = dataset_to_indices(train_urdu, train_english, urdu_vocab, english_vocab)\nval_urdu_indices, val_english_indices = dataset_to_indices(val_urdu, val_english, urdu_vocab, english_vocab)\ntest_urdu_indices, test_english_indices = dataset_to_indices(test_urdu, test_english, urdu_vocab, english_vocab)\n\n# Save preprocessed data\ntrain_preprocessed = pd.DataFrame({'urdu': train_urdu_indices, 'english': train_english_indices})\nval_preprocessed = pd.DataFrame({'urdu': val_urdu_indices, 'english': val_english_indices})\ntest_preprocessed = pd.DataFrame({'urdu': test_urdu_indices, 'english': test_english_indices})\n\ntrain_preprocessed.to_csv('train_preprocessed.csv', index=False)\nval_preprocessed.to_csv('val_preprocessed.csv', index=False)\ntest_preprocessed.to_csv('test_preprocessed.csv', index=False)\n\nprint(\"Preprocessed data saved as 'train_preprocessed.csv', 'val_preprocessed.csv', and 'test_preprocessed.csv'.\")\n\n\n\n# Print first 5 samples of indexed data\nprint(\"\\nIndexed Urdu Sentences:\\n\", train_urdu_indices.head())\nprint(\"\\nIndexed English Sentences:\\n\", train_english_indices.head())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7jcYZqwxKI9q","outputId":"99bb3e5e-7767-4c93-ac86-f8989f4428c4","trusted":true,"execution":{"iopub.status.busy":"2024-12-10T14:05:05.301630Z","iopub.execute_input":"2024-12-10T14:05:05.302762Z","iopub.status.idle":"2024-12-10T14:05:05.401081Z","shell.execute_reply.started":"2024-12-10T14:05:05.302677Z","shell.execute_reply":"2024-12-10T14:05:05.399588Z"}},"outputs":[{"name":"stdout","text":"Preprocessed data saved as 'train_preprocessed.csv', 'val_preprocessed.csv', and 'test_preprocessed.csv'.\n\nIndexed Urdu Sentences:\n 0    [1, 42, 10, 82, 14, 777, 7, 19, 3151, 11, 1506...\n1    [1, 3154, 4, 331, 8, 3155, 332, 33, 3156, 18, ...\n2    [1, 398, 18, 16, 482, 12, 38, 1511, 154, 3159,...\n3    [1, 679, 30, 954, 2042, 11, 16, 4, 49, 6, 2043...\n4    [1, 1512, 4, 166, 4, 155, 4, 485, 778, 8, 2044...\nName: urdu, dtype: object\n\nIndexed English Sentences:\n 0    [1, 320, 1307, 1901, 11, 3171, 8, 373, 63, 317...\n1    [1, 53, 40, 3177, 374, 7, 3178, 6, 4, 430, 190...\n2    [1, 321, 3183, 16, 508, 4, 322, 285, 1904, 318...\n3    [1, 13, 1310, 16, 1311, 3187, 8, 4, 623, 1312,...\n4    [1, 3188, 16, 114, 774, 7, 1907, 36, 141, 7, 9...\nName: english, dtype: object\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport random\n\nimport pandas as pd\n\n# Load preprocessed data\n\nval_data = pd.read_csv('val_preprocessed.csv')\n\n# Extract the src (Urdu) and trg (English) sequences\ntrain_data = pd.read_csv('train_preprocessed.csv')\ntrain_src = train_data['urdu'].apply(eval).tolist()\ntrain_trg = train_data['english'].apply(eval).tolist()\n\nval_src = val_data['urdu'].apply(eval).tolist()\nval_trg = val_data['english'].apply(eval).tolist()\n\n\n\n\n# Custom LSTM Cell\nclass LSTMCell(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(LSTMCell, self).__init__()\n        self.hidden_dim = hidden_dim\n\n        self.W_i = nn.Linear(input_dim, hidden_dim)  # Input gate\n        self.W_f = nn.Linear(input_dim, hidden_dim)  # Forget gate\n        self.W_o = nn.Linear(input_dim, hidden_dim)  # Output gate\n        self.W_c = nn.Linear(input_dim, hidden_dim)  # Cell state gate\n\n    def forward(self, input, hidden, cell):\n        # Hidden state and cell state\n        h, c = hidden, cell\n\n        # Gates\n        i = torch.sigmoid(self.W_i(input))\n        f = torch.sigmoid(self.W_f(input))\n        o = torch.sigmoid(self.W_o(input))\n        c_tilde = torch.tanh(self.W_c(input))\n\n        # Update cell state and hidden state\n        c = f * c + i * c_tilde\n        h = o * torch.tanh(c)\n\n        return h, c\n\n# Encoder with Custom LSTM Cell\nclass CustomLSTMEncoder(nn.Module):\n    def __init__(self, input_dim, embed_dim, hidden_dim):\n        super(CustomLSTMEncoder, self).__init__()\n        self.embedding = nn.Embedding(input_dim, embed_dim)\n        self.hidden_dim = hidden_dim\n        self.lstm_cell = LSTMCell(embed_dim, hidden_dim)\n\n    def forward(self, src):\n        embedded = self.embedding(src)  # Shape: (batch_size, seq_len, embed_dim)\n        batch_size = embedded.size(0)\n        seq_len = embedded.size(1)\n\n        hidden = torch.zeros(batch_size, self.hidden_dim).to(src.device)\n        cell = torch.zeros(batch_size, self.hidden_dim).to(src.device)\n\n        encoder_outputs = []\n\n        for t in range(seq_len):\n            hidden, cell = self.lstm_cell(embedded[:, t, :], hidden, cell)\n            encoder_outputs.append(hidden)\n\n        encoder_outputs = torch.stack(encoder_outputs, dim=1)  # Shape: (batch_size, seq_len, hidden_dim)\n        return encoder_outputs, (hidden, cell)\n\n# Attention Mechanism\n# Attention Mechanism\nclass Attention(nn.Module):\n    def __init__(self, hidden_dim):\n        super(Attention, self).__init__()\n        self.hidden_dim = hidden_dim\n        self.W_a = nn.Linear(hidden_dim, hidden_dim)\n        self.v = nn.Linear(hidden_dim, 1)\n\n    def forward(self, encoder_outputs, decoder_hidden):\n        # Adjust the shape of decoder_hidden to match encoder_outputs\n        decoder_hidden = decoder_hidden.unsqueeze(1)  # Shape: (batch_size, 1, hidden_dim)\n\n        # Compute the attention scores\n        scores = self.v(torch.tanh(self.W_a(encoder_outputs) + decoder_hidden)).squeeze(-1)\n\n        # Apply softmax to get attention weights\n        attention_weights = F.softmax(scores, dim=1)  # Shape: (batch_size, seq_len)\n\n        # Compute the context vector as the weighted sum of encoder outputs\n        context_vector = torch.sum(attention_weights.unsqueeze(2) * encoder_outputs, dim=1)  # Shape: (batch_size, hidden_dim)\n\n        return context_vector, attention_weights\n\n# Decoder with Custom LSTM Cell\n# Decoder with Custom LSTM Cell\nclass CustomLSTMDecoder(nn.Module):\n    def __init__(self, output_dim, embed_dim, hidden_dim):\n        super(CustomLSTMDecoder, self).__init__()\n        self.embedding = nn.Embedding(output_dim, embed_dim)\n        self.hidden_dim = hidden_dim\n        self.lstm_cell = LSTMCell(embed_dim + hidden_dim, hidden_dim)  # LSTM with combined input and context vector\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, input, decoder_hidden, context_vector):\n        embedded = self.embedding(input).unsqueeze(1)  # Shape: (batch_size, 1, embed_dim)\n        combined = torch.cat((embedded, context_vector.unsqueeze(1)), dim=2)  # Shape: (batch_size, 1, embed_dim + hidden_dim)\n        output, hidden = self.lstm_cell(combined.squeeze(1), decoder_hidden[0], decoder_hidden[1])  # Corrected unpacking\n        output = self.fc(output)  # Shape: (batch_size, output_dim)\n        return output, (hidden, hidden)  # Return hidden and hidden for consistency\n\n\n# Seq2Seq Model with Custom LSTM Cells and Attention\nclass CustomLSTMSeq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, attention):\n        super(CustomLSTMSeq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.attention = attention\n\n    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n        batch_size = src.size(0)\n        trg_len = trg.size(1)\n        trg_vocab_size = self.decoder.fc.out_features\n\n        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(src.device)\n\n        # Encoder outputs\n        encoder_outputs, (hidden, cell) = self.encoder(src)\n\n        # Decoder input (starting with <sos> token)\n        input = trg[:, 0]  # The first token for each batch is <sos>\n\n        # Initial decoder hidden state\n        decoder_hidden = (hidden, cell)\n\n        for t in range(1, trg_len):\n            # Attention\n            context_vector, _ = self.attention(encoder_outputs, decoder_hidden[0])\n\n            # Decoder forward pass\n            output, decoder_hidden = self.decoder(input, decoder_hidden, context_vector)\n\n            # Store the output\n            outputs[:, t, :] = output\n\n            # Get the most probable word and use as input for next timestep (teacher forcing)\n            top1 = output.argmax(1)\n            input = top1 if random.random() < teacher_forcing_ratio else trg[:, t]\n\n        return outputs\n\n\n\n\n# Example Hyperparameters\nINPUT_DIM = len(urdu_vocab)  # Example vocab size for source language (e.g. Urdu)\nOUTPUT_DIM = len(english_vocab)  # Example vocab size for target language (e.g. English)\nEMBED_DIM = 256\nHIDDEN_DIM = 512\n\n# Create Encoder, Decoder, Attention, and Seq2Seq Model\nencoder = CustomLSTMEncoder(INPUT_DIM, EMBED_DIM, HIDDEN_DIM)\ndecoder = CustomLSTMDecoder(OUTPUT_DIM, EMBED_DIM, HIDDEN_DIM)\nattention = Attention(HIDDEN_DIM)\n\nmodel = CustomLSTMSeq2Seq(encoder, decoder, attention)\n\n# Specify device (CPU or GPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Define the device\n\n# Move the model to the device\nmodel = model.to(device)\n\n# Optimizer and Loss function\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\ncriterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding index (0)\n\n# Training loop\n# Training loop\n# Adjust the train and evaluate function for correct data format\ndef train(model, train_src, train_trg, val_src, val_trg, epochs=10, batch_size=32, teacher_forcing_ratio=0.5):\n    model.train()\n    for epoch in range(epochs):\n        epoch_loss = 0\n        for i in range(0, len(train_src), batch_size):  # Loop over training data\n            batch_src = torch.tensor(train_src[i:i+batch_size]).to(device)\n            batch_trg = torch.tensor(train_trg[i:i+batch_size]).to(device)\n\n            optimizer.zero_grad()\n\n            output = model(batch_src, batch_trg, teacher_forcing_ratio)\n            output_dim = output.shape[-1]\n            output = output[:, 1:, :].contiguous().view(-1, output_dim)  # Skip <sos> (1st token)\n\n            # Adjust target shape to match the output\n            trg = batch_trg[:, 1:].contiguous().view(-1)  # Skip <sos> (1st token)\n\n            # Check if the shapes match\n            assert output.shape[0] == trg.shape[0], f\"Output shape {output.shape[0]} does not match target shape {trg.shape[0]}\"\n\n            loss = criterion(output, trg)\n            loss.backward()\n            optimizer.step()\n\n            epoch_loss += loss.item()\n\n        print(f'Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(train_src)}')\n\n        # Evaluate on validation data after each epoch\n        evaluate(model, val_src, val_trg, batch_size)\n\n\ndef evaluate(model, val_src, val_trg, batch_size):\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for i in range(0, len(val_src), batch_size):\n            batch_src = torch.tensor(val_src[i:i+batch_size]).to(device)\n            batch_trg = torch.tensor(val_trg[i:i+batch_size]).to(device)\n\n            output = model(batch_src, batch_trg, teacher_forcing_ratio=0)\n            output_dim = output.shape[-1]\n            output = output[:, 1:, :].contiguous().view(-1, output_dim)  # Skip <sos> (1st token)\n\n            # Skip <sos> token from target sequence\n            trg = batch_trg[:, 1:].contiguous().view(-1)  # Skip <sos> (1st token)\n\n            # Ensure the target and output sizes are the same\n            assert output.shape[0] == trg.shape[0], f\"Output shape {output.shape[0]} does not match target shape {trg.shape[0]}\"\n\n            loss = criterion(output, trg)\n            val_loss += loss.item()\n\n    print(f'Validation Loss: {val_loss / len(val_src)}')\n\n\n# Example: Start training\ntrain(model, train_src, train_trg, val_src, val_trg, epochs=5, batch_size=32, teacher_forcing_ratio=0.5)\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JKi6DKibJdzu","outputId":"3d13f750-330e-4aa8-cdfc-13c4f3468aa6","trusted":true,"execution":{"iopub.status.busy":"2024-12-10T14:10:03.184165Z","iopub.execute_input":"2024-12-10T14:10:03.184570Z","iopub.status.idle":"2024-12-10T14:26:49.459654Z","shell.execute_reply.started":"2024-12-10T14:10:03.184538Z","shell.execute_reply":"2024-12-10T14:26:49.458156Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5, Loss: 0.22592131443756233\nValidation Loss: 0.22539847712976196\nEpoch 2/5, Loss: 0.20869831611557332\nValidation Loss: 0.22872842427504023\nEpoch 3/5, Loss: 0.20325961051930067\nValidation Loss: 0.23185210212124543\nEpoch 4/5, Loss: 0.19725058021111305\nValidation Loss: 0.2336385368904798\nEpoch 5/5, Loss: 0.19204806365804009\nValidation Loss: 0.23464615400447403\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import torch\nimport random\n\ndef translate(model, src, trg_vocab, max_len=50):\n    model.eval()\n    with torch.no_grad():\n        # The input to the decoder should be <sos> token (start of sequence)\n        input = src[0]  # Assume src is a single sentence here (batch size 1)\n        output_sentence = []\n\n        # Initial hidden and cell states of the decoder\n        encoder_outputs, (hidden, cell) = model.encoder(src.unsqueeze(0))  # Add batch dimension\n        decoder_hidden = (hidden, cell)\n\n        # Start with the <sos> token\n        input = torch.tensor([trg_vocab['<sos>']]).to(device)\n\n        for t in range(max_len):\n            context_vector, _ = model.attention(encoder_outputs, decoder_hidden[0])\n            output, decoder_hidden = model.decoder(input, decoder_hidden, context_vector)\n\n            # Get the most probable token\n            top1 = output.argmax(1)\n\n            # Append to the generated sequence\n            output_sentence.append(top1.item())\n\n            # Stop if we generate the <eos> token\n            if top1.item() == trg_vocab['<eos>']:\n                break\n\n            input = top1  # Use the generated word as the input for the next timestep\n\n        return output_sentence\n\n# Example: Translate the test set\ntest_data = pd.read_csv('test_preprocessed.csv')\ntest_src = test_data['urdu'].apply(eval).tolist()\ntest_trg = test_data['english'].apply(eval).tolist()\n\ntest_translations = []\nfor src_sentence in test_src:\n    translation = translate(model, torch.tensor(src_sentence).to(device), english_vocab)\n    test_translations.append(translation)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T14:29:28.813757Z","iopub.execute_input":"2024-12-10T14:29:28.814566Z","iopub.status.idle":"2024-12-10T14:29:47.448722Z","shell.execute_reply.started":"2024-12-10T14:29:28.814510Z","shell.execute_reply":"2024-12-10T14:29:47.447164Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from nltk.translate.bleu_score import corpus_bleu\n\n# Prepare references for BLEU evaluation (each reference is a list of words)\nreferences = [[trg] for trg in test_trg]  # Wrap each target translation in a list\n\n# Compute BLEU score\nbleu_score = corpus_bleu(references, test_translations)\nprint(f'BLEU Score: {bleu_score}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T14:29:48.958575Z","iopub.execute_input":"2024-12-10T14:29:48.959014Z","iopub.status.idle":"2024-12-10T14:29:49.007921Z","shell.execute_reply.started":"2024-12-10T14:29:48.958977Z","shell.execute_reply":"2024-12-10T14:29:49.006770Z"}},"outputs":[{"name":"stdout","text":"BLEU Score: 0.012018732047514769\n","output_type":"stream"}],"execution_count":12}]}